{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9FFvPqFMq-L"
      },
      "source": [
        "# Extracting frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pGGAUVJoM38l",
        "outputId": "a4a7df19-9898-40ae-abd6-d768b31f879b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=b1125445d1897b46fe1ebf0fea8c27f7a8e791dc9723da1eb5c87ad3936aab16\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "pip install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M11Z2tHrffIV",
        "outputId": "c3fdd11b-64fb-495b-9010-5e52e209c7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1etK70h6Mqdk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "from PIL import Image\n",
        "\n",
        "def extract_frames(video_path, output_folder, interval=1):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Load the video clip\n",
        "    clip = VideoFileClip(video_path)\n",
        "\n",
        "    # Calculate the frame extraction times in seconds\n",
        "    frame_times = [t for t in range(0, int(clip.duration), interval)]\n",
        "\n",
        "    # Extract frames at each specified time\n",
        "    for t in frame_times:\n",
        "        frame = clip.get_frame(t)\n",
        "        output_path = os.path.join(output_folder, f\"frame_{t}.jpg\")\n",
        "        image = Image.fromarray(frame)\n",
        "        image.save(output_path)\n",
        "\n",
        "    # Close the original clip\n",
        "    clip.close()\n",
        "\n",
        "# Example usage\n",
        "video_path = \"/content/drive/MyDrive/video2.mp4\"\n",
        "output_folder = \"/content/framess\"\n",
        "extract_frames(video_path, output_folder, interval=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "collapsed": true,
        "id": "YmD8tXaYe2ju",
        "outputId": "6665ad7f-8332-471b-8b08-e7ffe6ab43d3"
      },
      "outputs": [
        {
          "ename": "CalledProcessError",
          "evalue": "Command '['ffmpeg', '-i', '/content/drive/MyDrive/video2.mp4', '-vf', 'fps=2071/duration', '/content/drive/MyDrive/framess/frame_%04d.png']' returned non-zero exit status 1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7815370bf180>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2071\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mextract_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-7815370bf180>\u001b[0m in \u001b[0;36mextract_frames\u001b[0;34m(video_path, output_folder, num_frames)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Run FFmpeg command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    527\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-i', '/content/drive/MyDrive/video2.mp4', '-vf', 'fps=2071/duration', '/content/drive/MyDrive/framess/frame_%04d.png']' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def extract_frames(video_path, output_folder, num_frames):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # FFmpeg command to extract frames\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', video_path,                # Input file\n",
        "        '-vf', f'fps={num_frames}/duration',  # Extract frames evenly distributed\n",
        "        os.path.join(output_folder, 'frame_%04d.png')  # Output frames\n",
        "    ]\n",
        "\n",
        "    # Run FFmpeg command\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/drive/MyDrive/video2.mp4'\n",
        "output_folder = '/content/framess'\n",
        "num_frames = 2071\n",
        "\n",
        "extract_frames(video_path, output_folder, num_frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf6puZA1K4cb",
        "outputId": "e89d969d-5e44-48a0-877c-60fe03323301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODf9fkrV09Tj"
      },
      "source": [
        "# Installing the dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jsrilQoW9yKZ",
        "outputId": "707dcaee-0747-4f5e-f6d4-8791f9dde94c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autodistill\n",
            "  Downloading autodistill-0.1.28-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting autodistill-grounded-sam\n",
            "  Downloading autodistill_grounded_sam-0.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting autodistill-yolov8\n",
            "  Downloading autodistill_yolov8-0.1.4-py3-none-any.whl.metadata (995 bytes)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from autodistill) (4.8.0.76)\n",
            "Collecting supervision (from autodistill)\n",
            "  Downloading supervision-0.22.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autodistill) (4.66.4)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from autodistill) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from autodistill) (6.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autodistill) (8.1.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from autodistill-grounded-sam) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from autodistill-grounded-sam) (1.25.2)\n",
            "Collecting rf-groundingdino (from autodistill-grounded-sam)\n",
            "  Downloading rf_groundingdino-0.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting rf-segment-anything (from autodistill-grounded-sam)\n",
            "  Downloading rf_segment_anything-1.0-py3-none-any.whl.metadata (583 bytes)\n",
            "Collecting ultralytics==8.0.81 (from autodistill-yolov8)\n",
            "  Downloading ultralytics-8.0.81-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (3.7.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (1.11.4)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (0.18.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (0.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.81->autodistill-yolov8) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.81->autodistill-yolov8)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting sentry-sdk (from ultralytics==8.0.81->autodistill-yolov8)\n",
            "  Downloading sentry_sdk-2.11.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->autodistill-grounded-sam)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->autodistill-grounded-sam) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->autodistill-grounded-sam)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from rf-groundingdino->autodistill-grounded-sam) (4.42.4)\n",
            "Collecting addict (from rf-groundingdino->autodistill-grounded-sam)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting yapf (from rf-groundingdino->autodistill-grounded-sam)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from rf-groundingdino->autodistill-grounded-sam)\n",
            "  Downloading timm-1.0.7-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from rf-groundingdino->autodistill-grounded-sam) (2.0.8)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->autodistill) (0.7.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision->autodistill) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.81->autodistill-yolov8) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.81->autodistill-yolov8) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.81->autodistill-yolov8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.81->autodistill-yolov8) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.81->autodistill-yolov8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.81->autodistill-yolov8) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->autodistill-grounded-sam) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->autodistill-grounded-sam) (1.3.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->rf-groundingdino->autodistill-grounded-sam) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->rf-groundingdino->autodistill-grounded-sam) (0.4.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->rf-groundingdino->autodistill-grounded-sam) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->rf-groundingdino->autodistill-grounded-sam) (0.19.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->rf-groundingdino->autodistill-grounded-sam) (8.0.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->rf-groundingdino->autodistill-grounded-sam) (4.2.2)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->rf-groundingdino->autodistill-grounded-sam) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->rf-groundingdino->autodistill-grounded-sam) (3.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics==8.0.81->autodistill-yolov8) (1.16.0)\n",
            "Downloading autodistill-0.1.28-py3-none-any.whl (31 kB)\n",
            "Downloading autodistill_grounded_sam-0.1.2-py3-none-any.whl (8.7 kB)\n",
            "Downloading autodistill_yolov8-0.1.4-py3-none-any.whl (14 kB)\n",
            "Downloading ultralytics-8.0.81-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.0/527.0 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading rf_groundingdino-0.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m193.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rf_segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Downloading supervision-0.22.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading sentry_sdk-2.11.0-py2.py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.6/303.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rf-segment-anything, addict, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, yapf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, supervision, nvidia-cusolver-cu12, autodistill, thop, ultralytics, timm, rf-groundingdino, autodistill-yolov8, autodistill-grounded-sam\n",
            "Successfully installed addict-2.4.0 autodistill-0.1.28 autodistill-grounded-sam-0.1.2 autodistill-yolov8-0.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 rf-groundingdino-0.2.0 rf-segment-anything-1.0 sentry-sdk-2.11.0 supervision-0.22.0 thop-0.1.1.post2209072238 timm-1.0.7 ultralytics-8.0.81 yapf-0.40.2\n"
          ]
        }
      ],
      "source": [
        "pip install autodistill autodistill-grounded-sam autodistill-yolov8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bQRVM5xh-vwk",
        "outputId": "1ff642f3-efc9-4b5d-b0e1-d3eba788aa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.36-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.36-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, chardet, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "Successfully installed chardet-4.0.0 filetype-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.36\n"
          ]
        }
      ],
      "source": [
        "pip install roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPWAwxz1IDM"
      },
      "source": [
        "# Labelling the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "21ae64f63758416e831a63ba9e4532b6",
            "62bc8944677343bfbb1c15c2651233b1",
            "569d06c69eaf4154a7d2cc08269a7913",
            "0ea89feea2184393b2b98692b586e3e2",
            "0e27400810714ed9b3eebfddb3a219fa",
            "7ebb2fcc5f954fb788812f35d2249a0e",
            "d714c1aeb9884a119a3b6c83079bae07",
            "80715fa32b7841a99d7103aa7e264ebd",
            "9291675a459849c494315b647875f2b5",
            "0c83b7badced42f68c9e3c3a57f9bbc5",
            "09931aaf9ddd483bbd89ebe1b3085f04",
            "d748e428c5d24ce687d88279c757e907",
            "4f998bed76554ab8acadb797c274b73c",
            "d9db9064a01743c180acc044be89f498",
            "17747f8c4d7c4bea9980606aa883a107",
            "2badfeaef57d44a88f4f08a963e4f1b1",
            "be7feeb0b00e45cc93de8ccc0f81b617",
            "1b55d17f26d04dbe92a694ec11b16e8b",
            "03e1349415a844ff9df8e1e7b579f318",
            "56a61a2bd8d2401da10b68ed9def6d7e",
            "03db2d9579c8402a841d21132eb02b01",
            "3430013844114c3d9aa3b1105b0cb6f6",
            "2ef68fac74b14a448bc50989da4968d8",
            "65cbc85bca3748db8f021f3386cfd63d",
            "e1ccb610dd064c3aa13495321eb27dd8",
            "6934f027f0e84afbbd86c84174b9d834",
            "65a1af5deadb4e5ab441d74974e08656",
            "618fc095eab2469e815f354a93fa7b1b",
            "00c5e03e9eba43f5aae5e1e01e02aaa7",
            "dd0f315784f44ae9a4d977a20e2eee28",
            "a2e10477fc884629aa3cd3df5aa049ae",
            "3fb8911c1eb14cecbbf50ad7264c27bb",
            "a764e46a470f45aba9cf8e94767745df",
            "6374995896fc431387aa4ffd0283952d",
            "0167e977e2f64a83affe8531fa9e2995",
            "eb8b70dad1ee4436960d3e7fc2dfde95",
            "cfdd615b5441473b95719badef5eb29f",
            "a2339d7c794b4a38b51c6b45ffa897ab",
            "77abecb935084422bae4c37a386d5f9c",
            "0b0c1a781b6947cba7faa38e01617b23",
            "a7a70f744295409e9da2ea5a97e89afe",
            "ff9c158e3b8243388cd57cc609651a8a",
            "db5367f08c8648fd9aafba4823b27421",
            "698422ac02c640198226e81bbc21f1ef",
            "c97a42abdfb44efdb0c7ebeedd73e70a",
            "f4f489c4a65f4c64b665f55452743fd3",
            "d56e56a99977441cbdd88bd4f42ac10a",
            "fbdb5e5e004341e7971db1b0bb5491df",
            "bb8d682730e848c3bd4cc27947aa9b41",
            "85cfedc5c0a14ba98ee2c45e04acd127",
            "25c14971ae5d4de48b1cdf872786f53f",
            "fb9ffdf811c949dfb841d75aea9af631",
            "1a36bc52f9824897871bb060f11f0ae9",
            "022dbfadede2460fbb372b268846361b",
            "51145b1925dc44639c8f8e9d53e08830"
          ]
        },
        "collapsed": true,
        "id": "fXvk87KF94m3",
        "outputId": "27fc1e37-ad00-4025-e950-5628754e303e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: CUDA not available. GroundingDINO will run very slowly.\n",
            "trying to load grounding dino directly\n",
            "downloading dino model weights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ae64f63758416e831a63ba9e4532b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d748e428c5d24ce687d88279c757e907",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ef68fac74b14a448bc50989da4968d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6374995896fc431387aa4ffd0283952d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c97a42abdfb44efdb0c7ebeedd73e70a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Labeling /content/drive/MyDrive/datasetforlabel/frames1/framesfinal/frame_1079.jpg:   0%|          | 0/1772 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "Labeling /content/drive/MyDrive/datasetforlabel/frames1/framesfinal/frame_1077.jpg:   0%|          | 1/1772 [02:01<59:41:30, 121.34s/it]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "Labeling /content/drive/MyDrive/datasetforlabel/frames1/framesfinal/frame_1111.jpg:   2%|▏         | 35/1772 [1:05:40<53:23:34, 110.66s/it]    "
          ]
        }
      ],
      "source": [
        "\n",
        "##Labelling of first 16 frames of first video from the dataset\n",
        "\n",
        "import os\n",
        "import supervision as sv\n",
        "import cv2\n",
        "import shutil\n",
        "from autodistill.detection import CaptionOntology\n",
        "from autodistill_grounded_sam import GroundedSAM\n",
        "\n",
        "# Define the ontology\n",
        "ontology = CaptionOntology({\n",
        "   \"license plate\" : \"license plate\"\n",
        "})\n",
        "\n",
        "IMAGES = \"/content/drive/MyDrive/datasetforlabel/frames1/framesfinal\"\n",
        "DATASET_DIR_PATH = \"/content/drive/MyDrive/datasetforlabel/dataset\"\n",
        "\n",
        "# Delete folder if it already exists\n",
        "if os.path.exists(DATASET_DIR_PATH):\n",
        "    shutil.rmtree(DATASET_DIR_PATH)\n",
        "\n",
        "# Initialize the base model with the ontology\n",
        "# We're using the GroundedSAM as our base model\n",
        "base_model = GroundedSAM(ontology=ontology)\n",
        "\n",
        "try:\n",
        "    # Label the images\n",
        "    dataset = base_model.label(\n",
        "        input_folder=IMAGES,\n",
        "        extension=\".jpg\",\n",
        "        output_folder=DATASET_DIR_PATH\n",
        "    )\n",
        "\n",
        "    print(\"Labeling completed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during labeling: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N8SJ6hbYF5PW",
        "outputId": "37908eef-4453-4d3c-9a27-2103acc44d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.36-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m994.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Installing collected packages: filetype, python-dotenv, chardet, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "Successfully installed chardet-4.0.0 filetype-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.36\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in conversio-to-yolo-1 to yolov8:: 100%|██████████| 6105/6105 [00:00<00:00, 6402.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to conversio-to-yolo-1 in yolov8:: 100%|██████████| 202/202 [00:00<00:00, 6735.75it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"wMIqnBgpzlmciNfWNM0A\")\n",
        "project = rf.workspace(\"anjelica-q9xkn\").project(\"conversio-to-yolo\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSLluWAC1Pwu"
      },
      "source": [
        "# Training target model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required package for YOLOv8!\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LntwC84y2s_x",
        "outputId": "71b231fb-e86a-47d3-f062-fc5f2a730bab",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.81)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autodistill_yolov8 import YOLOv8\n",
        "\n",
        "target_model = YOLOv8(\"/content/drive/MyDrive/fine tune/best (1).pt\")\n",
        "target_model.train(\"/content/drive/MyDrive/fine tune/dataset/data.yaml\", epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjh3mLwq47qu",
        "outputId": "61f49f42-ff95-4645-c5cb-b0ab23b71e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.65 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.81 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/fine tune/best (1).pt, data=/content/drive/MyDrive/fine tune/dataset/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100%|██████████| 755k/755k [00:00<00:00, 111MB/s]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fine tune/dataset/train/labels.cache... 552 images, 30 backgrounds, 0 corrupt: 100%|██████████| 552/552 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fine tune/dataset/valid/labels.cache... 138 images, 5 backgrounds, 0 corrupt: 100%|██████████| 138/138 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20         0G      1.439      2.122      1.071         20        640: 100%|██████████| 35/35 [06:58<00:00, 11.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [03:00<00:00, 36.00s/it]\n",
            "                   all        138        186       0.85      0.547      0.685      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20         0G      1.223      1.325     0.9701         20        640: 100%|██████████| 35/35 [06:31<00:00, 11.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
            "                   all        138        186      0.787      0.674      0.734      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20         0G       1.19      1.254     0.9452         12        640: 100%|██████████| 35/35 [06:20<00:00, 10.87s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:19<00:00,  3.97s/it]\n",
            "                   all        138        186      0.759      0.695      0.757      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/20         0G      1.196      1.174     0.9302         15        640: 100%|██████████| 35/35 [06:26<00:00, 11.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:19<00:00,  3.97s/it]\n",
            "                   all        138        186      0.773      0.642      0.767      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/20         0G      1.151      1.229     0.9293         18        640: 100%|██████████| 35/35 [06:23<00:00, 10.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:19<00:00,  4.00s/it]\n",
            "                   all        138        186       0.87      0.645      0.744       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/20         0G      1.221      1.237      0.919         20        640: 100%|██████████| 35/35 [06:26<00:00, 11.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.18s/it]\n",
            "                   all        138        186      0.914      0.629      0.795      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/20         0G      1.135      1.141     0.9249         20        640: 100%|██████████| 35/35 [06:33<00:00, 11.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.19s/it]\n",
            "                   all        138        186      0.773      0.645      0.763      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/20         0G      1.064      1.127     0.9126         22        640: 100%|██████████| 35/35 [06:39<00:00, 11.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.21s/it]\n",
            "                   all        138        186      0.874      0.661      0.796      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/20         0G      1.067      1.102     0.9084         24        640: 100%|██████████| 35/35 [06:31<00:00, 11.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
            "                   all        138        186      0.792      0.667      0.786      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/20         0G      1.012      1.068     0.8853         11        640: 100%|██████████| 35/35 [06:36<00:00, 11.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.37s/it]\n",
            "                   all        138        186      0.869      0.661      0.797      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/20         0G      1.026      1.065     0.9057         22        640: 100%|██████████| 35/35 [06:36<00:00, 11.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.16s/it]\n",
            "                   all        138        186      0.822      0.721      0.801      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/20         0G      1.007      1.026     0.8917         11        640: 100%|██████████| 35/35 [06:43<00:00, 11.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.19s/it]\n",
            "                   all        138        186      0.846       0.71      0.827      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/20         0G     0.9371      1.015     0.8886         20        640: 100%|██████████| 35/35 [06:38<00:00, 11.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:22<00:00,  4.46s/it]\n",
            "                   all        138        186       0.84      0.726      0.822      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/20         0G     0.9014     0.9357     0.8791         19        640: 100%|██████████| 35/35 [06:46<00:00, 11.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:22<00:00,  4.50s/it]\n",
            "                   all        138        186      0.843      0.747      0.839       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/20         0G     0.9056     0.9315     0.8614         19        640: 100%|██████████| 35/35 [06:40<00:00, 11.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.33s/it]\n",
            "                   all        138        186      0.805      0.731      0.836      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/20         0G     0.9019     0.9245     0.8689         15        640: 100%|██████████| 35/35 [06:35<00:00, 11.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.07s/it]\n",
            "                   all        138        186      0.835      0.731      0.835      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/20         0G     0.8958      0.918     0.8657         16        640: 100%|██████████| 35/35 [06:32<00:00, 11.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:20<00:00,  4.04s/it]\n",
            "                   all        138        186      0.836      0.739      0.836      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/20         0G     0.8787     0.8993     0.8666         16        640: 100%|██████████| 35/35 [06:36<00:00, 11.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.39s/it]\n",
            "                   all        138        186      0.883      0.732      0.848      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/20         0G     0.8173     0.8681     0.8519          9        640: 100%|██████████| 35/35 [06:38<00:00, 11.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.25s/it]\n",
            "                   all        138        186      0.875      0.731      0.848      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/20         0G     0.8096     0.8289     0.8505         14        640: 100%|██████████| 35/35 [06:30<00:00, 11.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:22<00:00,  4.46s/it]\n",
            "                   all        138        186      0.807      0.758      0.847      0.683\n",
            "\n",
            "20 epochs completed in 2.361 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.81 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:21<00:00,  4.28s/it]\n",
            "                   all        138        186      0.807      0.758      0.847      0.684\n",
            "Speed: 1.3ms preprocess, 98.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xDJsRtN1Yrl"
      },
      "source": [
        "# Running inference on video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C7hMA64Bz_EI",
        "outputId": "2acaf0ea-9ff6-4ef7-c6a1-92329e1af5c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDpUGpErT9Xb",
        "outputId": "c31ce4f2-5c37-4dc0-bd22-1d700b06f8b4",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 0.7ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.2ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.7ms preprocess, 11.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.7ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 12.6ms\n",
            "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.1ms\n",
            "Speed: 0.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.6ms\n",
            "Speed: 0.6ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.3ms\n",
            "Speed: 0.7ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 16.2ms\n",
            "Speed: 0.6ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.0ms\n",
            "Speed: 0.9ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.8ms\n",
            "Speed: 0.6ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.7ms\n",
            "Speed: 0.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 7.5ms\n",
            "Speed: 0.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.7ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.6ms\n",
            "Speed: 0.7ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 1.4ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 15.2ms\n",
            "Speed: 0.6ms preprocess, 15.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 license plates, 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 10.2ms\n",
            "Speed: 0.5ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.5ms\n",
            "Speed: 0.5ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.2ms\n",
            "Speed: 0.5ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.0ms\n",
            "Speed: 0.6ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 21.0ms\n",
            "Speed: 0.8ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.6ms\n",
            "Speed: 0.7ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.1ms\n",
            "Speed: 0.6ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.6ms\n",
            "Speed: 0.7ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 6.6ms\n",
            "Speed: 0.6ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.5ms\n",
            "Speed: 0.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.1ms\n",
            "Speed: 0.6ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.8ms\n",
            "Speed: 0.7ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.8ms\n",
            "Speed: 1.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.2ms\n",
            "Speed: 1.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 8.7ms\n",
            "Speed: 0.7ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.3ms\n",
            "Speed: 0.6ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.1ms\n",
            "Speed: 0.5ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.5ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 6.4ms\n",
            "Speed: 0.5ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.5ms\n",
            "Speed: 1.6ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.8ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.8ms preprocess, 14.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.4ms\n",
            "Speed: 0.7ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.9ms\n",
            "Speed: 0.7ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.3ms\n",
            "Speed: 0.6ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.1ms\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.8ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.7ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 0.6ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.7ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.9ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 4.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.0ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.5ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.4ms\n",
            "Speed: 0.6ms preprocess, 18.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.3ms\n",
            "Speed: 0.7ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.7ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.0ms\n",
            "Speed: 0.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 6.9ms\n",
            "Speed: 0.6ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.9ms\n",
            "Speed: 0.6ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 1.4ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.8ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.7ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.4ms\n",
            "Speed: 0.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 6.8ms\n",
            "Speed: 0.6ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.9ms\n",
            "Speed: 0.7ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.3ms\n",
            "Speed: 1.2ms preprocess, 18.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.1ms\n",
            "Speed: 1.6ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 20.6ms\n",
            "Speed: 0.6ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.2ms\n",
            "Speed: 0.7ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.2ms\n",
            "Speed: 0.6ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.0ms\n",
            "Speed: 0.6ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.2ms\n",
            "Speed: 0.7ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.7ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 license plates, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 license plates, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 license plates, 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 13.5ms\n",
            "Speed: 0.7ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.5ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.2ms\n",
            "Speed: 1.0ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.8ms\n",
            "Speed: 1.6ms preprocess, 12.8ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 17.0ms\n",
            "Speed: 0.6ms preprocess, 17.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 16.6ms\n",
            "Speed: 0.6ms preprocess, 16.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.4ms\n",
            "Speed: 0.6ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.4ms\n",
            "Speed: 0.6ms preprocess, 17.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 15.1ms\n",
            "Speed: 1.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.9ms\n",
            "Speed: 5.0ms preprocess, 12.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.9ms\n",
            "Speed: 0.6ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.9ms\n",
            "Speed: 0.5ms preprocess, 10.9ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 license plates, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 21.7ms\n",
            "Speed: 0.6ms preprocess, 21.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 19.4ms\n",
            "Speed: 0.7ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 license plates, 10.1ms\n",
            "Speed: 0.5ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.5ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.0ms\n",
            "Speed: 0.5ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.5ms\n",
            "Speed: 0.5ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 0.6ms preprocess, 16.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 20.2ms\n",
            "Speed: 0.7ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.1ms\n",
            "Speed: 0.7ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 30.2ms\n",
            "Speed: 0.6ms preprocess, 30.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 2.4ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 0.6ms preprocess, 17.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.7ms\n",
            "Speed: 0.5ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.4ms\n",
            "Speed: 0.6ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 1.1ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 0.6ms preprocess, 18.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 0.6ms preprocess, 18.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 0.6ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.1ms\n",
            "Speed: 4.8ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 0.6ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 0.7ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 0.7ms preprocess, 21.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.8ms\n",
            "Speed: 1.0ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 5.5ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.8ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 0.6ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.7ms preprocess, 16.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.6ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.7ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.5ms\n",
            "Speed: 0.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 1.1ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 0.5ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.4ms\n",
            "Speed: 0.6ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.5ms\n",
            "Speed: 1.2ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.0ms\n",
            "Speed: 0.8ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.7ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.3ms\n",
            "Speed: 0.5ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.5ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 0.6ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 1.2ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 0.7ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 0.6ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.7ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.7ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.8ms\n",
            "Speed: 0.7ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.7ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 5.0ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.7ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.8ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.0ms\n",
            "Speed: 0.8ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 0.6ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 21.8ms\n",
            "Speed: 0.6ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.6ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.6ms\n",
            "Speed: 0.5ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 0.6ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.7ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.6ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.5ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.5ms preprocess, 8.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 0.5ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.9ms\n",
            "Speed: 0.6ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 0.7ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.5ms\n",
            "Speed: 0.7ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.6ms\n",
            "Speed: 0.7ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.5ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.5ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.1ms\n",
            "Speed: 0.7ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.6ms\n",
            "Speed: 1.3ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.0ms\n",
            "Speed: 1.2ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.5ms\n",
            "Speed: 0.6ms preprocess, 18.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 8.9ms\n",
            "Speed: 4.7ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.0ms\n",
            "Speed: 0.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.5ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.7ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 1.2ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 1.1ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.5ms\n",
            "Speed: 0.7ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.0ms\n",
            "Speed: 0.6ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.5ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.8ms\n",
            "Speed: 0.5ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.6ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.2ms\n",
            "Speed: 0.8ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 16.6ms\n",
            "Speed: 1.4ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 14.8ms\n",
            "Speed: 0.7ms preprocess, 14.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.0ms\n",
            "Speed: 4.0ms preprocess, 14.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.0ms\n",
            "Speed: 0.6ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.5ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.1ms\n",
            "Speed: 0.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.2ms\n",
            "Speed: 0.5ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.0ms\n",
            "Speed: 0.7ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 25.1ms\n",
            "Speed: 0.6ms preprocess, 25.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.4ms\n",
            "Speed: 0.5ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.5ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.5ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.6ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.7ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.8ms\n",
            "Speed: 0.6ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 0.6ms preprocess, 18.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.6ms preprocess, 20.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.5ms\n",
            "Speed: 0.6ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.5ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.2ms\n",
            "Speed: 0.5ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.6ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.7ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 0.5ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.5ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 2.9ms preprocess, 20.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.3ms\n",
            "Speed: 3.0ms preprocess, 19.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 0.6ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 0.6ms preprocess, 21.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.1ms\n",
            "Speed: 0.5ms preprocess, 21.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 0.6ms preprocess, 17.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 0.6ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.5ms\n",
            "Speed: 0.6ms preprocess, 20.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 0.6ms preprocess, 18.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.8ms\n",
            "Speed: 0.6ms preprocess, 20.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 0.7ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.6ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 0.6ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 0.6ms preprocess, 20.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 0.6ms preprocess, 18.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 0.6ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 0.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.2ms\n",
            "Speed: 0.6ms preprocess, 21.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 7.7ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.4ms\n",
            "Speed: 0.5ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.6ms\n",
            "Speed: 1.3ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.0ms\n",
            "Speed: 1.5ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.6ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 5.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.3ms\n",
            "Speed: 0.5ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.6ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.1ms\n",
            "Speed: 0.7ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.6ms\n",
            "Speed: 0.9ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.1ms\n",
            "Speed: 0.7ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.6ms\n",
            "Speed: 3.8ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.5ms\n",
            "Speed: 0.6ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.8ms\n",
            "Speed: 0.7ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.9ms\n",
            "Speed: 0.5ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.1ms\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 1.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.7ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 19.7ms\n",
            "Speed: 0.6ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.9ms\n",
            "Speed: 0.7ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.8ms\n",
            "Speed: 7.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.7ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.0ms\n",
            "Speed: 0.6ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.1ms\n",
            "Speed: 0.7ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.4ms\n",
            "Speed: 1.6ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.2ms\n",
            "Speed: 2.2ms preprocess, 18.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.1ms\n",
            "Speed: 0.6ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.4ms\n",
            "Speed: 0.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.5ms\n",
            "Speed: 0.7ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.7ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.7ms\n",
            "Speed: 0.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.5ms\n",
            "Speed: 0.5ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 19.1ms\n",
            "Speed: 0.7ms preprocess, 19.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.3ms\n",
            "Speed: 1.6ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.4ms\n",
            "Speed: 1.4ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.0ms\n",
            "Speed: 0.7ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.1ms\n",
            "Speed: 0.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.9ms\n",
            "Speed: 0.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.1ms\n",
            "Speed: 0.6ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.4ms\n",
            "Speed: 0.8ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.7ms\n",
            "Speed: 1.4ms preprocess, 18.7ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.3ms\n",
            "Speed: 0.7ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.1ms\n",
            "Speed: 1.2ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.7ms\n",
            "Speed: 0.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 7.2ms\n",
            "Speed: 0.8ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.2ms\n",
            "Speed: 0.7ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.9ms\n",
            "Speed: 0.5ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.5ms\n",
            "Speed: 0.6ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.0ms\n",
            "Speed: 0.6ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.9ms\n",
            "Speed: 0.7ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.1ms\n",
            "Speed: 4.7ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.7ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.1ms\n",
            "Speed: 0.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.4ms\n",
            "Speed: 0.8ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.1ms\n",
            "Speed: 0.8ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.7ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.2ms\n",
            "Speed: 0.6ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.4ms\n",
            "Speed: 0.6ms preprocess, 15.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 0.7ms preprocess, 17.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 0.6ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 0.6ms preprocess, 16.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.9ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.7ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.7ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.0ms\n",
            "Speed: 1.2ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 0.8ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 1.8ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.6ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.6ms\n",
            "Speed: 1.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.1ms\n",
            "Speed: 0.8ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.6ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.4ms\n",
            "Speed: 0.7ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.8ms\n",
            "Speed: 1.5ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.3ms\n",
            "Speed: 0.6ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.1ms\n",
            "Speed: 0.5ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.5ms preprocess, 9.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.4ms\n",
            "Speed: 0.5ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.3ms\n",
            "Speed: 0.5ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 18.5ms\n",
            "Speed: 0.5ms preprocess, 18.5ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 17.9ms\n",
            "Speed: 0.7ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 17.2ms\n",
            "Speed: 0.6ms preprocess, 17.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 18.6ms\n",
            "Speed: 0.6ms preprocess, 18.6ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.0ms\n",
            "Speed: 0.6ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.1ms\n",
            "Speed: 0.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 license plates, 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 16.4ms\n",
            "Speed: 0.6ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.2ms\n",
            "Speed: 0.5ms preprocess, 10.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 11.7ms\n",
            "Speed: 0.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.6ms\n",
            "Speed: 0.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.9ms\n",
            "Speed: 0.5ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 28.8ms\n",
            "Speed: 0.5ms preprocess, 28.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.4ms\n",
            "Speed: 0.5ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.8ms\n",
            "Speed: 0.5ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 0.5ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.9ms\n",
            "Speed: 0.5ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.0ms\n",
            "Speed: 0.6ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.5ms\n",
            "Speed: 0.6ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 22.9ms\n",
            "Speed: 0.6ms preprocess, 22.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.8ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 20.2ms\n",
            "Speed: 0.6ms preprocess, 20.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.4ms\n",
            "Speed: 0.6ms preprocess, 18.4ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 19.4ms\n",
            "Speed: 0.6ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.8ms\n",
            "Speed: 0.6ms preprocess, 11.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.1ms\n",
            "Speed: 0.5ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.7ms\n",
            "Speed: 0.5ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 22.8ms\n",
            "Speed: 0.6ms preprocess, 22.8ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.1ms\n",
            "Speed: 0.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.1ms\n",
            "Speed: 0.5ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.2ms\n",
            "Speed: 0.5ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.3ms\n",
            "Speed: 0.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.2ms\n",
            "Speed: 0.5ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.0ms\n",
            "Speed: 0.6ms preprocess, 13.0ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 13.2ms\n",
            "Speed: 0.6ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 16.9ms\n",
            "Speed: 0.5ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.7ms\n",
            "Speed: 0.5ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.5ms preprocess, 8.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.5ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.0ms\n",
            "Speed: 0.5ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 0.5ms preprocess, 16.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.2ms\n",
            "Speed: 0.6ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.9ms\n",
            "Speed: 0.7ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 18.2ms\n",
            "Speed: 8.6ms preprocess, 18.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 3.6ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.5ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.1ms\n",
            "Speed: 0.6ms preprocess, 17.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 15.4ms\n",
            "Speed: 0.6ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 14.5ms\n",
            "Speed: 0.7ms preprocess, 14.5ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.1ms\n",
            "Speed: 0.5ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.4ms\n",
            "Speed: 0.6ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 20.9ms\n",
            "Speed: 1.2ms preprocess, 20.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 24.5ms\n",
            "Speed: 0.6ms preprocess, 24.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 0.7ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 0.6ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.4ms\n",
            "Speed: 0.6ms preprocess, 18.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 15.9ms\n",
            "Speed: 5.6ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 17.7ms\n",
            "Speed: 0.5ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.7ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.7ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.8ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.6ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.6ms preprocess, 12.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 0.6ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 0.6ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.6ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.7ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 0.6ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 0.6ms preprocess, 20.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.5ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 0.7ms preprocess, 17.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.2ms\n",
            "Speed: 0.7ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 0.6ms preprocess, 21.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 1.4ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 0.6ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 1.2ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.8ms\n",
            "Speed: 0.6ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.7ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 0.6ms preprocess, 18.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 0.7ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.7ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.9ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.5ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 0.5ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.6ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 0.6ms preprocess, 16.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 1.1ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 5.3ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.1ms\n",
            "Speed: 0.5ms preprocess, 21.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 1.6ms preprocess, 17.3ms inference, 11.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.6ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.6ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 0.5ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.1ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.6ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.5ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 0.5ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 1.3ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.7ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.7ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.5ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.6ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 0.6ms preprocess, 18.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.6ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.8ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 0.7ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 1.3ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 1.3ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.5ms\n",
            "Speed: 1.8ms preprocess, 26.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.6ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.9ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.3ms preprocess, 17.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.7ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.7ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 4.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.5ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.0ms\n",
            "Speed: 1.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.8ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.8ms\n",
            "Speed: 1.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.8ms\n",
            "Speed: 1.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 0.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.8ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.7ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.7ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 4.7ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 1.0ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.7ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.7ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 0.6ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.7ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 0.6ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 1.3ms preprocess, 17.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.8ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.5ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 0.7ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.8ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 0.7ms preprocess, 18.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 0.5ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.7ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.7ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.6ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.5ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 1.0ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.5ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.5ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.8ms\n",
            "Speed: 0.5ms preprocess, 20.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.5ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.5ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.8ms preprocess, 8.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.5ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.8ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.7ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 1.3ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.6ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.0ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.6ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 0.6ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 0.6ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 0.7ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 0.6ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.5ms\n",
            "Speed: 0.6ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 0.8ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.7ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 0.6ms preprocess, 20.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 0.5ms preprocess, 19.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 0.6ms preprocess, 17.8ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.7ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.0ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 0.6ms preprocess, 17.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.7ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 0.6ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 0.6ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 1.4ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 0.6ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 2.7ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 0.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.7ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 0.6ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.4ms\n",
            "Speed: 0.6ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 3.6ms preprocess, 16.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.6ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.0ms\n",
            "Speed: 0.6ms preprocess, 20.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.5ms\n",
            "Speed: 0.6ms preprocess, 23.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 0.6ms preprocess, 21.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 0.6ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 0.6ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 0.5ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.8ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 0.8ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 1.4ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 1.6ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.7ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.7ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 0.7ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.8ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 0.7ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.5ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.7ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.6ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 0.6ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.9ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 1.5ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 1.5ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.7ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 0.6ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.7ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 0.6ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.7ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 1.4ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 0.6ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 0.6ms preprocess, 21.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.7ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.6ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.1ms\n",
            "Speed: 1.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.3ms\n",
            "Speed: 0.5ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 0.6ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.7ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 0.7ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 14.7ms\n",
            "Speed: 0.6ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 license plates, 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.6ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.8ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 11.5ms\n",
            "Speed: 0.7ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 12.4ms\n",
            "Speed: 5.6ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.7ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.5ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.4ms\n",
            "Speed: 0.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.9ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 0.6ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.8ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.5ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.7ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 license plate, 9.2ms\n",
            "Speed: 0.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.5ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 0.5ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.5ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.7ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.6ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.1ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 0.5ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.8ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 0.6ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.5ms\n",
            "Speed: 0.7ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.7ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.6ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 0.6ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 0.5ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 1.2ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.5ms\n",
            "Speed: 0.8ms preprocess, 22.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 0.7ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 5.1ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.8ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.6ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.7ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.7ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 0.6ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.6ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 0.6ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.5ms preprocess, 15.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.2ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 4.4ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 0.5ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.5ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.2ms\n",
            "Speed: 0.6ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.6ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 2.7ms preprocess, 22.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 4.6ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 0.5ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.5ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 0.6ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 0.6ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 0.6ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.6ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 0.6ms preprocess, 18.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 0.6ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.4ms\n",
            "Speed: 0.8ms preprocess, 22.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 0.6ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 0.6ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.5ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 0.6ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 0.6ms preprocess, 16.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 0.6ms preprocess, 18.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.5ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.5ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 5.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 0.5ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.8ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.5ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.9ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 0.7ms preprocess, 18.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 0.6ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 0.7ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 0.5ms preprocess, 17.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 0.6ms preprocess, 20.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 8.5ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.5ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 0.6ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.8ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.7ms preprocess, 8.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 0.6ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 3.8ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.7ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 7.2ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 0.6ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 0.7ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.7ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 0.6ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 0.6ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 0.6ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 0.6ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 0.6ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.6ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 0.7ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 0.7ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.6ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.6ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.5ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 0.6ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 0.5ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 0.7ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 0.6ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.9ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.5ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 0.5ms preprocess, 8.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.7ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.5ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.7ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.6ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.8ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 0.6ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 0.7ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 0.6ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.7ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.6ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.6ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 0.6ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.5ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.8ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 0.7ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 0.9ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.6ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.6ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.7ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 0.6ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 0.6ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.8ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 0.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.6ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 0.8ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.5ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.9ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 0.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.5ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.7ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.7ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 0.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 0.7ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 0.6ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.7ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 0.6ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.6ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 0.6ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 0.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.7ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 0.6ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 0.5ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 0.6ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 0.6ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.6ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 0.6ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 1.1ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 0.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 0.6ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 0.5ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 0.6ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 0.6ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 0.6ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 0.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 0.6ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 0.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 0.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 1.5ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 1.4ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 0.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 0.6ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 0.5ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 0.6ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 0.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 0.6ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 0.7ms preprocess, 9.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 0.5ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 0.5ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.6ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 0.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.7ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 0.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 0.7ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 0.7ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 0.5ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 0.8ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 0.6ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 0.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 0.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 0.6ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 0.7ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 0.7ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 0.6ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 0.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 0.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 0.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 0.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 0.6ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 0.6ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 0.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 0.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 0.5ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 0.6ms preprocess, 14.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 0.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/runs/detect/train/weights/best.pt\")\n",
        "box_annotator = sv.BoundingBoxAnnotator()\n",
        "\n",
        "def callback(frame: np.ndarray, _: int) -> np.ndarray:\n",
        "    results = model(frame)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    return box_annotator.annotate(frame.copy(), detections=detections)\n",
        "\n",
        "sv.process_video(\n",
        "    source_path=\"/content/drive/MyDrive/video2.mp4\",\n",
        "    target_path=\"/content/drive/MyDrive/output.mp4\",\n",
        "    callback=callback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmNyoux4QEaA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMjoar_kQEXL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJz5_rjeQEQa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOs6zbtzQEHn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIi-BYbvQAyQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "VymG8g7hHamU",
        "outputId": "9d3057ca-1490-4bf0-ac08-c2f189f6e441"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=\"/content/drive/MyDrive/autolabel/runs/detect/train/val_batch0_labels.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9b73b3lgxun"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I684Rn7fgxkM"
      },
      "outputs": [],
      "source": [
        "!pip install -qq  autodistill\n",
        "!pip install -qq  autodistill-grounded-sam\n",
        "!pip install -qq  roboflow\n",
        "!pip install -qq  supervision==0.9.0\n",
        "#!pip install -qq git+https://github.com/pytube/pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EOjYGi-g_oh"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import os\n",
        "from autodistill.detection import CaptionOntology\n",
        "from autodistill_grounded_sam import GroundedSAM\n",
        "\n",
        "import glob\n",
        "from pytube import YouTube\n",
        "\n",
        "import IPython.display as display\n",
        "from IPython.display import Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvgXhtIOgxNs"
      },
      "outputs": [],
      "source": [
        "def annot_wrapper_to_video(image_names, video_properties,out_video_name = './output.mp4', temp_path_video = './temp.mp4'):\n",
        "    mask_annotator = sv.MaskAnnotator()\n",
        "    box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "    out = cv2.VideoWriter(\n",
        "        temp_path_video,\n",
        "        cv2.VideoWriter_fourcc(*'MP4V'),\n",
        "        video_properties['fps']/2,\n",
        "        (video_properties['width'], video_properties['height']))\n",
        "\n",
        "    for image_name in image_names:\n",
        "        image = dataset.images[image_name]\n",
        "        annotations = dataset.annotations[image_name]\n",
        "        labels = [\n",
        "            dataset.classes[class_id]\n",
        "            for class_id\n",
        "            in annotations.class_id]\n",
        "        annotates_image = mask_annotator.annotate(\n",
        "            scene=image.copy(),\n",
        "            detections=annotations)\n",
        "        annotates_image = box_annotator.annotate(\n",
        "            scene=annotates_image,\n",
        "            detections=annotations,\n",
        "            labels=labels)\n",
        "\n",
        "\n",
        "        out.write(annotates_image)\n",
        "    out.release()\n",
        "\n",
        "    if os.path.exists(out_video_name):\n",
        "        os.remove(out_video_name)\n",
        "\n",
        "    subprocess.run(\n",
        "    [\n",
        "        \"ffmpeg\",  \"-i\", temp_path_video, \"-crf\",\n",
        "        \"18\", \"-preset\", \"veryfast\", \"-hide_banner\", \"-loglevel\",\n",
        "        \"error\", \"-vcodec\", \"libx264\", out_video_name\n",
        "    ])\n",
        "    os.remove(temp_path_video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlu-vVb4hHq4"
      },
      "outputs": [],
      "source": [
        "out_video_name = './output.mp4'\n",
        "annot_wrapper_to_video(list(dataset.images.keys()),\n",
        "                      video_properties = video_properties,\n",
        "                       out_video_name = out_video_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciFO6xUWhISI"
      },
      "outputs": [],
      "source": [
        "Video(data=out_video_name, embed=True, height=int(video_properties['height'] * 0.5), width=int(video_properties['width'] * 0.5))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c5e03e9eba43f5aae5e1e01e02aaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0167e977e2f64a83affe8531fa9e2995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77abecb935084422bae4c37a386d5f9c",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0c1a781b6947cba7faa38e01617b23",
            "value": "tokenizer.json: 100%"
          }
        },
        "022dbfadede2460fbb372b268846361b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03db2d9579c8402a841d21132eb02b01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e1349415a844ff9df8e1e7b579f318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09931aaf9ddd483bbd89ebe1b3085f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0c1a781b6947cba7faa38e01617b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c83b7badced42f68c9e3c3a57f9bbc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e27400810714ed9b3eebfddb3a219fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea89feea2184393b2b98692b586e3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c83b7badced42f68c9e3c3a57f9bbc5",
            "placeholder": "​",
            "style": "IPY_MODEL_09931aaf9ddd483bbd89ebe1b3085f04",
            "value": " 48.0/48.0 [00:00&lt;00:00, 759B/s]"
          }
        },
        "17747f8c4d7c4bea9980606aa883a107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03db2d9579c8402a841d21132eb02b01",
            "placeholder": "​",
            "style": "IPY_MODEL_3430013844114c3d9aa3b1105b0cb6f6",
            "value": " 570/570 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "1a36bc52f9824897871bb060f11f0ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b55d17f26d04dbe92a694ec11b16e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ae64f63758416e831a63ba9e4532b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62bc8944677343bfbb1c15c2651233b1",
              "IPY_MODEL_569d06c69eaf4154a7d2cc08269a7913",
              "IPY_MODEL_0ea89feea2184393b2b98692b586e3e2"
            ],
            "layout": "IPY_MODEL_0e27400810714ed9b3eebfddb3a219fa"
          }
        },
        "25c14971ae5d4de48b1cdf872786f53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2badfeaef57d44a88f4f08a963e4f1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef68fac74b14a448bc50989da4968d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65cbc85bca3748db8f021f3386cfd63d",
              "IPY_MODEL_e1ccb610dd064c3aa13495321eb27dd8",
              "IPY_MODEL_6934f027f0e84afbbd86c84174b9d834"
            ],
            "layout": "IPY_MODEL_65a1af5deadb4e5ab441d74974e08656"
          }
        },
        "3430013844114c3d9aa3b1105b0cb6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb8911c1eb14cecbbf50ad7264c27bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f998bed76554ab8acadb797c274b73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7feeb0b00e45cc93de8ccc0f81b617",
            "placeholder": "​",
            "style": "IPY_MODEL_1b55d17f26d04dbe92a694ec11b16e8b",
            "value": "config.json: 100%"
          }
        },
        "51145b1925dc44639c8f8e9d53e08830": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569d06c69eaf4154a7d2cc08269a7913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80715fa32b7841a99d7103aa7e264ebd",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9291675a459849c494315b647875f2b5",
            "value": 48
          }
        },
        "56a61a2bd8d2401da10b68ed9def6d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "618fc095eab2469e815f354a93fa7b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62bc8944677343bfbb1c15c2651233b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebb2fcc5f954fb788812f35d2249a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_d714c1aeb9884a119a3b6c83079bae07",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6374995896fc431387aa4ffd0283952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0167e977e2f64a83affe8531fa9e2995",
              "IPY_MODEL_eb8b70dad1ee4436960d3e7fc2dfde95",
              "IPY_MODEL_cfdd615b5441473b95719badef5eb29f"
            ],
            "layout": "IPY_MODEL_a2339d7c794b4a38b51c6b45ffa897ab"
          }
        },
        "65a1af5deadb4e5ab441d74974e08656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65cbc85bca3748db8f021f3386cfd63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618fc095eab2469e815f354a93fa7b1b",
            "placeholder": "​",
            "style": "IPY_MODEL_00c5e03e9eba43f5aae5e1e01e02aaa7",
            "value": "vocab.txt: 100%"
          }
        },
        "6934f027f0e84afbbd86c84174b9d834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb8911c1eb14cecbbf50ad7264c27bb",
            "placeholder": "​",
            "style": "IPY_MODEL_a764e46a470f45aba9cf8e94767745df",
            "value": " 232k/232k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "698422ac02c640198226e81bbc21f1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77abecb935084422bae4c37a386d5f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebb2fcc5f954fb788812f35d2249a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80715fa32b7841a99d7103aa7e264ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cfedc5c0a14ba98ee2c45e04acd127": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9291675a459849c494315b647875f2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2339d7c794b4a38b51c6b45ffa897ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e10477fc884629aa3cd3df5aa049ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a764e46a470f45aba9cf8e94767745df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a70f744295409e9da2ea5a97e89afe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8d682730e848c3bd4cc27947aa9b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be7feeb0b00e45cc93de8ccc0f81b617": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97a42abdfb44efdb0c7ebeedd73e70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4f489c4a65f4c64b665f55452743fd3",
              "IPY_MODEL_d56e56a99977441cbdd88bd4f42ac10a",
              "IPY_MODEL_fbdb5e5e004341e7971db1b0bb5491df"
            ],
            "layout": "IPY_MODEL_bb8d682730e848c3bd4cc27947aa9b41"
          }
        },
        "cfdd615b5441473b95719badef5eb29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5367f08c8648fd9aafba4823b27421",
            "placeholder": "​",
            "style": "IPY_MODEL_698422ac02c640198226e81bbc21f1ef",
            "value": " 466k/466k [00:00&lt;00:00, 1.91MB/s]"
          }
        },
        "d56e56a99977441cbdd88bd4f42ac10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9ffdf811c949dfb841d75aea9af631",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a36bc52f9824897871bb060f11f0ae9",
            "value": 440449768
          }
        },
        "d714c1aeb9884a119a3b6c83079bae07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d748e428c5d24ce687d88279c757e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f998bed76554ab8acadb797c274b73c",
              "IPY_MODEL_d9db9064a01743c180acc044be89f498",
              "IPY_MODEL_17747f8c4d7c4bea9980606aa883a107"
            ],
            "layout": "IPY_MODEL_2badfeaef57d44a88f4f08a963e4f1b1"
          }
        },
        "d9db9064a01743c180acc044be89f498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03e1349415a844ff9df8e1e7b579f318",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56a61a2bd8d2401da10b68ed9def6d7e",
            "value": 570
          }
        },
        "db5367f08c8648fd9aafba4823b27421": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0f315784f44ae9a4d977a20e2eee28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ccb610dd064c3aa13495321eb27dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0f315784f44ae9a4d977a20e2eee28",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2e10477fc884629aa3cd3df5aa049ae",
            "value": 231508
          }
        },
        "eb8b70dad1ee4436960d3e7fc2dfde95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a70f744295409e9da2ea5a97e89afe",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff9c158e3b8243388cd57cc609651a8a",
            "value": 466062
          }
        },
        "f4f489c4a65f4c64b665f55452743fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85cfedc5c0a14ba98ee2c45e04acd127",
            "placeholder": "​",
            "style": "IPY_MODEL_25c14971ae5d4de48b1cdf872786f53f",
            "value": "model.safetensors: 100%"
          }
        },
        "fb9ffdf811c949dfb841d75aea9af631": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdb5e5e004341e7971db1b0bb5491df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022dbfadede2460fbb372b268846361b",
            "placeholder": "​",
            "style": "IPY_MODEL_51145b1925dc44639c8f8e9d53e08830",
            "value": " 440M/440M [00:02&lt;00:00, 229MB/s]"
          }
        },
        "ff9c158e3b8243388cd57cc609651a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}